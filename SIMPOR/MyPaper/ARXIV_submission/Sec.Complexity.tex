

%\section{Algorithm Implementation and Time Complexity}


\section{Algorithm Time Complexity.}
\label{sec:implementation}

\Copy{timeComplexity}{
\iffalse
Our proposed technique is straightforward in implementation. We first train a neural network model with initial samples and start querying the next batches of data based on the entropy scores from the previous model to find informative samples. The model is then updated with new batches of data until the entropy scores reach a certain threshold. All the informative samples are then balanced first, and the remaining data are balanced later. Each synthetic data point is generated by finding local maxima in Equation \ref{equ:f}.
\fi

The costly part of \Methodname{} is that each synthetic sample requires computing a kernel density estimation of the entire dataset. Elaborately, let $n$ be the number of samples of the dataset. In the worst case, the numbers of samples of minority and majority class are $N_B = 1$ and $N_A = n-1$, respectively. We need to generate $n-2$ synthetic samples to balance the dataset completely. Since each generated sample must loop through the entire dataset of size $n$ to estimate the density, the algorithm complexity is $O(n^2)$. 

Although generating synthetic data is only a one-time process, and this does not affect the classification efficiency in the testing phase, we still try to alleviate its weakness by providing parallelized implementations to reduce the time complexity to $O(n)$. Specifically, each exponential component in Equation \ref{equ:f} is computed parallelly, utilizing GPU or CPU threads. Ellaborately, Equation \ref{equ:f} can be rewritten as $N_B$ components of $e^{\frac{1}{2} (\frac {x - X_{B_i}}{h})^2}$ and $N_A$ components of $e^{\frac{1}{2} (\frac {x - X_{A_i}}{h})^2}$. Fortunately, they are all independent and can be processed parallelly. Thus, with a sufficient hardware resource, the consumption time for the kernel density estimation of each synthetic data point is then reduced by $N_A+N_B=n$ times, which significantly simplifies the complexity to $O(n)$.

}
