

\newcommand{\argmax}{{\operatorname{arg}\,\operatorname{max}}\;}
%\newcommand{\x}{$\times$}
\newcommand{\multirot}[3]{\multirow{#1}{*}{\rotatebox{#2}{ #3 } }}  %paras: rows,degree,text 


\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
	#1\;\delimsize\|\;#2%
}
\newcommand{\KL}{KL\infdivx}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

%\DeclareMathOperator*{\argmin}{\arg\min} 

\newcommand{\MethodnameLongSIMPOR}{Synthetic Information towards Maximum Posterior Ratio}
\newcommand{\Methodname}{SIMPOR}

\newcommand{\ChapterPathSIMPOR}{Chapter3}
\chapter{Synthetic Information Towards Maximum Posterior Ratio for Deep Learning on Class Imbalanced Data}
\label{chap:SIMPOR}



\section{Introduction}
Class imbalance is a common phenomenon; it could be caused by the data collecting procedure or simply the nature of the data. For example, it is difficult to sample some rare diseases in the medical field, so collected data for these are usually significantly less than that for other diseases. This leads to the problem of class imbalance in machine learning. The chance of rare samples appearing in model training process is much smaller than that of common samples. Thus, machine learning models tend to be dominated by the majority class; this results in a higher prediction error rate. Existing work also observed that class imbalanced data cause a slow convergence in the training process because of the domination of gradient vectors coming from the majority class \cite{ya-guan_emsgd:_2020, liu_high-performance_2020}. 

In the last decades, a number of techniques have been proposed to soften the negative effects of class imbalance for conventional machine learning algorithms by analytically studying particular algorithms and developing corresponding strategies. However, the problem for heuristic algorithms such as deep learning is often more difficult to tackle. As suggested in the most recent deep learning with class imbalance survey \cite{johnson_survey_2019}, most of the works are emphasizing image data, and studies for other data types are missing. Thus, in this work, we focus on addressing the issue of tabular data with class imbalance for deep learning models. We propose a class balancing solution that utilizes entropy-based sampling and data statistical information. As suggested in the survey (\cite{johnson_survey_2019}) that techniques for traditional ML can be extended to deep learning and inspiring by the comparison in a recent relevant work, Gaussian Distribution Based Oversampling (GDO) \cite{bib:GDO}, we compare the proposed technique with other widely-used and recent techniques such as GDO \cite{bib:GDO}, SMOTE \cite{chawla_smote:_2002}, ADASYN \cite{ADASYN}, Borderline SMOTE \cite{bordersmote}, Random Oversampling (ROS). 

We categorize existing solutions into model-centric and data-centric approaches in which the first approach aims at modifying machine algorithms, and the latter looks for data balancing techniques. Perhaps data-centric techniques are more commonly used because they do not tie to any specific model. In this category, a simple data balancing technique is to duplicate minority instances to balance the sample quantity between classes, namely random oversampling (ROS). This can preserve the best data structure and reduce the negative impact of data imbalance to some degree. However, this puts too much weight on a very few minority samples; as a result, it causes over-fitting problems in deep learning when the imbalance ratio becomes higher. 

Another widely-used technique in this category is Synthetic Minority Oversampling Technique (SMOTE) \cite{chawla_smote:_2002}, which randomly generates synthetic data on the connections (in Euclidean space) between minority samples. However, this easily breaks data topology, especially in high-dimensional space, because it can accidentally connect instances that are not supposed to be connected. In addition, if there are minority samples located in the majority class, the technique will generate sample lines across the decision boundary, which leads to distorted decision boundaries and misclassification. To improve SMOTE, Hui Han, \textit{et al.} \cite{bordersmote} proposed a SMOTE-based technique (Borderline SMOTE), in which they only apply SMOTE on the near-boundary samples determined by the labels of their neighbors. For example, if a sample Euclidean space-based group includes samples from other classes, they can be considered samples near the border. Since this technique is entirely based on Euclidean distance from determining neighbors to generating synthetic data, it performs poorly in high dimensional space. Similar to SMOTE, if there is any poorly generated sample near the boundary, it will worsen the problem due to synthetic samples bridges across the border. Leveraging the same way as SMOTE generates synthetic samples, another widely-used technique, ADASYN \cite{ADASYN}, controls the number of generated samples by the number of samples in different classes within small groups. Again, this technique still suffers distortion of the decision boundary if the boundary region is class imbalanced. Additionally, such mentioned techniques have not utilized statistical data information. A recent work, Gaussian Distribution Based Oversampling (GDO) \cite{bib:GDO}, balances data class based on the statistical information of data instead. However, its strong assumption of data distribution (data follow Gaussian) reduces the technique's effectiveness in real data.  

To alleviate the negative effects of data imbalance and avoid the drawbacks of existing techniques, we propose a minority oversampling technique that focuses on balancing the high-entropy region that provides the most critical information to the deep learning models. Besides, the technique enhances synthetic data's chance to fall into the minority class to reduce model errors. By carefully generating synthetic data near minority samples, our proposed technique also preserves the best data topology. Besides, our technique does not need any statistical assumption. 

To find informative samples, we leverage an entropy-based deep active learning technique that is able to select samples yielding high entropy to deep learning models. We denote the location of informative samples as the informative region. We then balance this region first, and the remaining data are balanced later so that it would reduce the decision distortion mentioned earlier. For each minority sample in this region, we safely generate its synthetic neighbors so that the global data topology is still preserved. However, generating synthetic samples in this region is risky because it can easily fall across the decision boundary. Therefore, we find a direction to generate synthetic samples by maximizing their posterior probability based on Bayes's Theorem. However, maximizing the posterior probability is facing infeasible computation in the denominator. To overcome this, we maximize the posterior ratio instead so that the denominator computation can be avoided. This also ensures that the synthetic samples are not only close to the minority class but also far from the majority class. The remaining data are eventually balanced by a similar procedure. 

The proposed technique alleviates the class imbalance problem. Our experiments indicate that we can achieve better classification results over widely-used techniques in all experimental cases by applying the proposed strategy.  

Our work has the following main contributions:
\begin{enumerate}
	\item{Exploring the impact of class imbalance mitigations on deep learning via visualization and experiments.}
	\item{Proposing a new minority oversampling-based technique, namely \MethodnameLongSIMPOR, to balance data classes and alleviate data imbalance impacts. Our technique is enhanced by the following key points.}
	\begin{enumerate}
		\item Leveraging an entropy-based active learning technique to prioritize the region that needs to be balanced. It is the informative region where samples provide high information entropy to the model. 
		\item Leveraging Maximum Posterior Ratio and Bayes's theorem to determine the direction to generate synthetic minority samples to ensure the synthetic data fall into the minority class and not fall across the decision boundary. To our best knowledge, this is the first work utilizing the posterior ratio for tackling class imbalanced data. 
		\item Approximating the likelihood in the posterior ratio using kernel density estimation, which can approximate a complicated topology. Thus, the proposed technique is able to work with large, distributively complex data. 
		\item Carefully generating synthetic samples surrounding minority samples so that the global data topology is still preserved. 
	\end{enumerate}
	\item{We applied our technique to 41 real datasets with a diversity of imbalance ratio and the number of features.}
	\item{We compare our technique with different widely-used and recent techniques. The results show that the proposed technique outperforms others.}
\end{enumerate}


The rest of this paper is organized as follows. Section \ref{sec:preliminaries} introduces related concepts that will be used in this work, i.e., Imbalance Ratio, Macro F1-score, AUC, and Entropy-based active learning. Section \ref{sec:problem} will provide more detail on the problem of learning from an imbalanced dataset. Our proposed solution to balance dataset, \MethodnameLongSIMPOR, will be explained comprehensively in Section \ref{sec:SIMPOR_method}. Section \ref{sec:implementation} discusses the technique implementation and complexity. We will show experiments on different datasets, including artificial and real datasets in Section \ref{sec:experiments}. We also discuss experimental results in the same section. In Section \ref{sec:relatedwork}, we briefly review other existing works. Section \ref{sec:conclusion} concludes the study and discusses future work. 

\section{Preliminaries}
\label{sec:preliminaries}       
In this section, we introduce related concepts that will be used in our work. 

\subsection{Imbalance Ratio (IR)}
For binary classification problems, we use imbalance ratio (IR) to depict the data imbalance as it has been widely used. IR is the ratio of the majority class samples to the minority class's samples. For example, if a dataset contains 1000 class-A and 100 class-B samples, the Imbalance Ratio is 10:1.   

\subsection{Evaluation Metrics}
\label{f1score}
In this work, we evaluate balancing data techniques by classification performance. Specifically, we use F1-Score and Area Under the Curve (AUC) as evaluation metrics. We measure the Macro-averaging for measuring F1-scores in which we compute scores per class and take the average of all classes with the same weight regardless of how often they appear in the datasets. These are fair measurements for imbalanced test datasets. 

F1 score is computed based on two factors Recall and Precision as follows:

\begin{align}
Recall &= \frac{TP}{TP+FN}\\
Precision &= \frac{TP}{TP+FP}\\
F1-score &= \frac{2*Recall*Precision}{Recall+Precision},
\end{align}
where $T$ and $F$ stand for True and False; $P$ and $N$ stand for Positive and Negative. 

We also measure AUC \cite{cite:AUC} scores as it is an important metric to evaluate imbalanced data. AUC is derived from Receiver Operating Characteristic curve (ROC). In this work, we utilize a skit-learn library to compute AUC; the library can be found in sklearn.metrics.auc. 


\subsection{Entropy-based Active Learning }   
\label{sec:EAL}
To find informative samples, we leverage entropy-based active learning. The technique gradually selects batch-by-batch samples that provide high information to the model based on information entropy theory \cite{shannon_mathematical_1948}. The information entropy is quantified based on the ``surprise" to the model in terms of class prediction probability. Take a binary classification, for example, if a sample is predicted to be 50\% belonging to class A and 50\% belonging to class B, this sample has high entropy and is informative to the model. In contrast, if it is predicted to be 100\% belonging to class A, it is certain and gives zero information to the model. The class entropy $E$ for each sample can be computed as follows. 

\begin{equation}
E(x,\theta) = -\sum_i^n{ P_\theta( y=c_i|x) \log_n P_\theta(y=c_i|x) }
\label{eq:entropy_AL}
\end{equation} 
where $P_\theta(y=c_i|x)$ is the probability of data $x$ belonging to the \textit{i}th class of $n$ classes with current model parameter $\theta$.

In this work, we consider a dataset containing $N$ pairs of samples $X$ and corresponding labels $y$, and a deep neural network with parameter $\theta$. At the first step $t^{(0)}$, we train the classifier with parameter $\theta^{(0)}$ on a random batch of $k$ labeled samples and use the $\theta^{(0)}$ to predict the labels for the rest of the data (we assume their labels are unknown). We then compute the prediction entropy of each sample based on Equation \ref{eq:entropy_AL}. We are now able to collect the first batch of informative samples by selecting $k$ samples based on the top $k$ highest entropy. We query labels for this batch and concatenate them to existing labeled data to train the classifier parameter $\theta^{(1)}$ in the next step $t^{(1)}$. Steps are repeated until the number of informative samples reaches a pre-set informative portion (IP). For example, $IP=0.3$ will select the top 30\% high entropy samples as informative samples.  

\section{The Problem of Learning From Imbalanced Datasets}
\label{sec:problem}
In this section, we review the problem of learning from imbalanced datasets. Although the problem may apply to different machine learning methods, we focus on deep learning in this work. 

\begin{figure}[t!]
	%[trim=left bottom right top, clip]
	\includegraphics[width=\linewidth, trim=300 150 310 120,clip]{\ChapterPathSIMPOR/Figures/proplem.pdf}
	\caption{Learning from imbalanced datasets}
	\label{fig:problem}
\end{figure}

Figure \ref{fig:problem} illustrates our problem on a binary classification. The imbalance in the informative region (light blue eclipse) could lead to classification errors. The dashed green line depicts the expected boundary, while the solid blue line is the model's boundary. Since the minority class lacks data in this region, the majority class will dominate the model even with a few noisy poorly-placed samples, which leads to a shift of the model's boundary. In contrast to the study by Ertekin \textit{et al.} \cite{ertekin_learning_2007} which assumes the informative region is more balanced by nature and proposes a solution that only classifies over the informative samples, our assumption is different. We consider the case that the informative region contains highly imbalanced data, which we believe happens in most real scenarios. The problem could be more severe in a more complex setting such as high-dimensional and topologically complex data. Therefore, we proposed a technique to tackle the problem of data imbalance by oversampling the minority class in an informative manner. The detail of our proposed technique will be described in Section \ref{sec:SIMPOR_method}.   
       


\input{\ChapterPathSIMPOR/Sec.RelatedWork}

\input{\ChapterPathSIMPOR/Sec.Methodology}

\input{\ChapterPathSIMPOR/Sec.Complexity}

\input{\ChapterPathSIMPOR/Sec.Experiments}



\section {Conclusion}
\label{sec:conclusion}
We propose a data balancing technique by generating synthetic data for minority samples maximizing the posterior ratio to embrace the chance they fall into the minority class and do not fall across the expected decision boundary. While maximizing the posterior ratio, we use kernel density estimation to estimate the likelihood so that it is able to work with complex distribution data without requiring data distribution assumptions. In addition, our technique leverage entropy-based active learning to find and balance the most informative samples. This is important to improve model performance as shown in our experiments on 41 real-world datasets. For future work, we would like to investigate the class imbalance for image data type and enhance our technique to adapt to image datasets.     

