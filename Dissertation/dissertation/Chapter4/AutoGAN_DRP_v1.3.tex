

\documentclass[final,5p,twocolumn]{elsarticle}


\usepackage{hyperref}
\usepackage{lipsum}
\bibliographystyle{elsarticle-num}

% correct bad hyphenation here
%\hyphenation{op-tical net-works semi-conduc-tor}


\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{cite} %not using this package for els
\usepackage{flexisym}
\usepackage{xcolor}
\usepackage{float}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{balance}
\biboptions{sort&compress}
\hypersetup{draft}
\usepackage{wrapfig}
\usepackage{afterpage}


\makeatletter
\def\ps@pprintTitle{%
	\let\@oddhead\@empty
	\let\@evenhead\@empty
	\let\@oddfoot\@empty
	\let\@evenfoot\@oddfoot
}
\makeatother

\begin{document}
	
	\newcommand{\argmin}[1]{\underset{#1}{\operatorname{arg}\,\operatorname{min}}\;}
	\newcommand{\minmax}[1]{\underset{#1}{\operatorname{min}\,\operatorname{max}}\;}	
	\newcommand{\prob}[1]{p_#1} 	
	
	\newtheorem{example}{\bf Example}
	\newtheorem{definition}{\bf Definition}
	\newtheorem{theorem}{\bf Theorem}
	\newtheorem{claim}{\bf Claim}
	\newtheorem{proposition}{\bf Proposition}
	\newtheorem{lemma}{\bf Lemma}
	\newtheorem{remark}{\bf Remark}
	\newtheorem{collolary}{\bf Collolary}
	
	
	\newcommand{\Name}{AutoGAN-based Dimension Reduction for Privacy Preservation}
	\newcommand{\shortName}{AGDRPP}
	
	
	
	\begin{frontmatter}
		
		\title{ AutoGAN-based Dimension Reduction for Privacy Preservation}
		
		\author[add1]{Hung Nguyen}
		\ead{nsh@mail.usf.edu}
		
		\author[add1]{Di Zhuang}
		\ead{zhuangdi1990@gmail.com}
		
		\author[add2]{Peiyuan Wu}
		%	\author[add2]{Peiyuan Wu\corref{correspondingauthor}}
		%	\cortext[correspondingauthor]{Corresponding author}
		\ead{peiyuanwu@ntu.edu.tw}
		
		\author[add1]{Morris Chang}
		\ead{morrisjchang@gmail.com}
		
		\address[add1]{University of South Florida, USA}
		\address[add2]{National Taiwan University, Taiwan}
		
		
		\begin{abstract}
			\label{sec:abstract}
			\input{sections/abstract.tex}			
		\end{abstract}
		
		\begin{keyword}
			Generative Adversarial Nets, Auto-encoder, neural-network, privacy preservation, dimension reduction, access control.
		\end{keyword}
		
	\end{frontmatter}	
	
	\section{Introduction}
	\label{sec:introduction}
	\input{sections/intro.tex}
	
	\section{Related Work}
	
	\subsection{Literature Review}
	\input{sections/literature_review}
	
	\subsection{Preliminaries}
	To enhance the distance between original and reconstructed data in our DR system, we utilize the structure of Generative Adversarial Network (GAN) \cite{Goodfellow2014} for data perturbation and deep Auto-encoder \cite{Baldi2012} for data reconstruction. The following sections briefly review Auto-encoder and GAN.
	\subsubsection{Auto-encoder}
	Auto-encoder is aimed at learning lower dimension representations of unsupervised data. Auto-encoder can be used for denoising and reducing data dimension. It can be implemented by two neural network components: \textit{encoder} and \textit{decoder}. The \textit{encoder} and \textit{decoder} perform reverse operations. The input of the \textit{encoder} is the original data while the output of the \textit{decoder} is expected to be similar to the input data. The middle layer extracts latent representation of original data that could be used for dimension reduction. An Auto-encoder training process can be described as a minimization problem of the auto-encoder's loss function $\mathcal{L(\cdot)}$:
	\begin{equation}
	\mathcal{L}(x,g(f(x)))
	\end{equation}
	where x is input data, f($\cdot$) is an encoding function, and g($\cdot$) is a decoding function.
	
	\subsubsection{GAN}
	Generative Adversarial Nets is aimed at approximating distribution $p_d$ of a dataset via a generative model. GAN simultaneously trains two components \textit{generator} $G$ and \textit{discriminator} $D$, and the input of $G$ is sampled from a prior distribution $p_z(z)$ through which $G$ generates fake samples similar to the real samples. At the same time, $D$ is trained to differentiate between fake samples and real samples, and send feedback to $G$ for improvement. GAN can be formed as a two-player minimax game with value function V(G,D):
	
	\begin{equation}
	\begin{split}
	\min_G \max_D{V(G,D)} = & E_{x \sim \prob{d}} [log(D(x))] + \\& E_{z\sim \prob{z} }[log( 1 - D( G(z) ))]
	\end{split}
	\end{equation}
	
	The two components, \textit{Generator} and \textit{Discriminator} can be built from neural networks (e.g., fully connected neural network, convolutional neural network). The goal of G is to reduce the accuracy of D. Meanwhile, the goal of D is to differentiate fake samples from real samples. These two components are trained until the discriminator cannot distinguish between generated samples and real samples.
	
	
	\section{Methodology} \label{methodology}
	
	In this section, we first describe the problem and threat model, then we introduce a definition of DR-Privacy and our dimensionality reduction method (AutoGAN-DRP).    
	\input{sections/problem}
	
	\subsection{$\epsilon$-Dimension Reduction Privacy ($\epsilon$-DR Privacy)} \label{theory}
	\input{sections/def}
	
	\input{sections/method.tex}
	
	\section{Experiments and Discussion}
	\input{sections/experiment.tex}
	
	\section{Conclusion}
	In this paper, we introduce a mathematical tool $\epsilon$-DR to evaluate privacy preserving mechanisms. We also propose a non-linear dimension reduction framework. This framework projects data onto lower dimension domain in which it prevents reconstruction attacks and preserves data utility. The dimension-reduced data can be used effectively for the machine learning tasks such as classification. In our future works, we plan to extend the framework to adapt with different types of data, such as time series and categorical data. We will apply different metrics to compute the distance other than $l_2$ norm and investigate the framework on several applications in security systems and data collaborative contributed systems.  
	
	\section*{Acknowledgment}
	This work is sponsored by DARPA Brandeis program under agreement number N66001-15-C-4068. The views, options, and/or findings contained in this article/presentation are those of the author/presenter and should not be interpreted as representing the official views or policies, either expressed or implied, of the Defense Advanced Research Projects Agency or the Department of Defense.  
	
	
	\bibliography{MyCollection}
	
	\balance 
	\begin{wrapfigure}{l}{24mm} 		\includegraphics[width=1.05in,height=1.8in,clip,keepaspectratio]{biography/hung_}
	\end{wrapfigure}\par
	\textbf{Hung Nguyen} received the M.Sc. degree and he is currently pursuing his Ph.D. degree in Department of Electrical Engineering, University of South Florida, FL, USA. His current research interests include machine learning techniques, artificial intelligence, cyber security, and privacy enhancing technologies. He is a student member of IEEE.\par 
	
	\begin{wrapfigure}{l}{24mm} 
		\includegraphics[width=1.05in,height=1.8in,clip,keepaspectratio]{biography/Zhuang_CP}
	\end{wrapfigure}\par
	\textbf{Di Zhuang} received the B.E. degree in computer science and information security from Nankai University, China. He is currently pursuing his Ph.D. degree in electrical engineering with University of South Florida, Tampa. His research interests include cyber security, social network science, privacy enhancing technologies, machine learning and big data analytics. He is a student member of IEEE.\\ \par
	
	\begin{wrapfigure}{l}{24mm} 
		\includegraphics[width=1.05in,height=1.8in,clip,keepaspectratio]{biography/Chang_CP}
	\end{wrapfigure}\par
	\textbf{J. Morris Chang} is a professor in the Department of Electrical Engineering at the University of South Florida. He received his Ph.D. degree from the North Carolina State University. He received the University Excellence in Teaching Award at Illinois Institute of Technology in 1999. His research interests include: cyber security, wireless networks, and energy efficient computer systems. In the last six years, his research projects on cyber security have been funded by DARPA. He is a handling editor of Journal of Microprocessors and Microsystems and an editor of IEEE IT Professional.\par
	
	
	\begin{wrapfigure}{l}{24mm} 
		\includegraphics[width=1.05in,height=1.8in,clip,keepaspectratio]{biography/peiyuanwu_black}
	\end{wrapfigure}\par
	\textbf{PeiYuan Wu} is an assistant professor at National Taiwan University since 2017. He was born in Taipei, Taiwan, R.O.C., in 1987. He received the B.S.E. degree in electrical engineering from National Taiwan University in 2009, and the M.A. and Ph.D. degrees in electrical engineering from Princeton University in 2012 and 2015, respectively. He joined Taiwan Semiconductor Manufacturing Company from 2015 to 2017. He was a recipient of the Gordon Y.S. Wu Fellowship in 2010, Outstanding Teaching Assistant Award at Princeton University in 2012. His research interest lies in artificial intelligence, signal processing, estimation and prediction, and cyber-physical system modeling.\par
	
\end{document}


